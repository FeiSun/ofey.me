
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
          "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">

<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en-us">
  <head>
    <meta http-equiv="content-type" content="text/html; charset=utf-8" />
    <!-- Favicon -->
	<link rel="shortcut icon" href="./images/favicon.ico" type="image/x-icon"/>

    <title>Fei Sun's Home Page</title>
    <meta name="author" content="Fei Sun" />

    <link rel="start" href="/" />


    <!-- syntax highlighting CSS -->
    <link rel="stylesheet" href="./css/syntax.css" type="text/css" />

    <!-- Homepage CSS -->
    <link rel="stylesheet" href="./css/screen.css" type="text/css" />
    <link rel="stylesheet" href="./css/print.css" type="text/css" media="print">
      <!-- Interactive elements (e.g., Javascript controlled) -->
      <link rel="stylesheet" href="./css/widgets.css" type="text/css" media="all" />

      <script src='./js/jquery.js' type='text/javascript'> </script>
      <script type='text/javascript'>
	    $(document).ready(function(){
		$("a:contains('BibTeX')").click(function(event) {
		$(this).parent().nextAll(".bibtex").first().slideToggle("fast"); });

		$("a:contains('BibTeX')").toggle(
		function(){ $(this).text("Hide BibTeX") },
		function(){ $(this).text("BibTeX") }
		);

		$("a:contains('Abstract')").click(function(event) {
		$(this).parent().nextAll(".abstract").first().slideToggle("fast"); });

		$("a:contains('Abstract')").toggle(
		function(){ $(this).text("Hide Abstract") },
		function(){ $(this).text("Abstract") }
		);

	    });
      </script>

      <script type="text/javascript">
        $(document).ready(function () {
        $("div.publication").hover(function() {
        // hover in
        $(this).addClass('highlight-title');
        }, function() {
        $(this).removeClass('highlight-title');
        });
        });
      </script>

      <script type="text/javascript">

        var _gaq = _gaq || [];
        _gaq.push(['_setAccount', 'UA-19401216-1']);
        _gaq.push(['_setDomainName', 'ofey.me']);
        _gaq.push(['_trackPageview']);

        (function() {
          var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
          ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
          var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
        })();

      </script>

    </head>
    <body id="Pubs">
      <div id="site">

        <div id="header">
          <h1>

    	    <a class="ofey" href="./" title="Home Page">Fei Sun</a>
    	    <!--<span class="byline">&larr; <a href="/">Fei Sun</a></span> !-->
          </h1>
          <ul class="nav">
            <li><a class="home" href="./index.html">Home</a></li>
            <li><a class="research" href="./research.html">Research</a></li>
            <li><a class ="pubs" href="./publication.html">Publications</a></li>
            <li><a  href="./resume/Fei Sun.pdf">Resume</a></li>
          </ul>
        </div>


        <div id="page">
          <h1 id="publications">Publications</h1>


          <h2 id='conference_papers'>Conference Papers</h2>

          <div class="section">
                      <h2 id="2015">2015</h2>

                      <div class="publication">
                        <div class="title-line">
                          Component-Enhanced Chinese Character Embeddings
                        </div>
                        <div class="author-line">
                        Yanran Li, Wenjie Li, <strong>Fei Sun </strong>, and Sujian Li
                        </div>
                        <div class="author-line">
                         The 2015 Conference on Empirical Methods in Natural Language Processing<br>
                            { <a href="./papers/emnlp2015comp.pdf">PDF</a> | <a href="">Abstract</a> | <a href="">BibTeX</a>}
                          </div>

                          <div class="abstract" style="display: none; ">
                            <h3 id="abstract">Abstract</h3>
                            <p>Distributed word representations are very useful for capturing semantic information and have been successfully applied in a variety of NLP tasks, especially on English.
                            In this work, we innovatively develop two component-enhanced Chinese character embedding models and their bigram extensions.
                            Distinguished from English word embeddings, our models explore the compositions of Chinese characters, which often serve as semantic indictors inherently.
                            The evaluations on both word similarity and text classification demonstrate the effectiveness of our models.
                             </p>
                          </div>
                          <div class="bibtex">
                            <h3 id="bibtex">BibTeX</h3>
                            <pre><code>
@InProceedings{li-EtAl:2015:EMNLP1,
  author    = {Li, Yanran  and  Li, Wenjie  and  Sun, Fei  and  Li, Sujian},
  title     = {Component-Enhanced Chinese Character Embeddings},
  booktitle = {Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing},
  month     = {September},
  year      = {2015},
  address   = {Lisbon, Portugal},
  publisher = {Association for Computational Linguistics},
  pages     = {829--834},
  url       = {http://aclweb.org/anthology/D15-1098}
}
                              </code>
{<a href="./bibtex/emnlp15.bib">download</a>}</pre>
                          </div>

                        </div>

                      <div class="publication">
                        <div class="title-line">
                          <a href="http://ofey.me/projects/wordrep/">
                          Learning Word Representations by Jointly Modeling Syntagmatic and Paradigmatic Relations
                        </a>
                        </div>
                        <div class="author-line">
                         <strong>Fei Sun </strong>, Jiafeng Guo, Yanyan Lan, Jun Xu and Xueqi Cheng
                        </div>
                        <div class="author-line">
                          The 53rd Annual Meeting of the Association for Computational Linguistics （ACL2015）<br>
                            { <a href="./papers/wordrep_acl2015.pdf">PDF</a> | <a href="https://github.com/FeiSun/WordRep">Code</a> | <a href="./slides/wordrep_acl2015.pdf">Slides</a> | <a href="">Abstract</a> | <a href="">BibTeX</a> }
                          </div>

                          <div class="abstract" style="display: none; ">
                            <h3 id="abstract">Abstract</h3>

                            <p>Vector space representation of words has been widely used to capture fine-grained linguistic regularities, and proven to be successful in various natural language processing tasks in recent years.
                              However, existing models for learning word representations focus on either syntagmatic or paradigmatic relations alone.
                              In this paper, we argue that it is beneficial to jointly modeling both relations so that we can not only encode different types of linguistic properties in a unified way, but also boost the representation learning due to the mutual enhancement between these two types of relations.
                              We propose two novel distributional models for word representation using both syntagmatic and paradigmatic relations via a joint training objective.
                              The proposed models are trained on a public Wikipedia corpus, and the learned representations are evaluated on word analogy and word similarity tasks.
                              The results demonstrate that the proposed models can perform significantly better than all the state-of-the-art baseline methods on both tasks.
                             </p>
                          </div>
                          <div class="bibtex">
                            <h3 id="bibtex">BibTeX</h3>
                            <pre><code>
@InProceedings{P15-1014,
author="Sun, Fei and Guo, Jiafeng and Lan, Yanyan and Xu, Jun and Cheng, Xueqi",
title="Learning Word Representations by Jointly Modeling Syntagmatic and Paradigmatic Relations",
booktitle="Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)",
year="2015",
publisher="Association for Computational Linguistics",
pages="136--145",
location="Beijing, China",
url="http://aclweb.org/anthology/P15-1014"
}
                              </code>
{<a href="./bibtex/wordrep-acl15.bib">download</a>}</pre>
                          </div>

                        </div>
                        <!--end of one paper-->

                      </div>


            <div class='section'>
              <h2 id=2011>2011</h2>

              <!--begin of one paper-->
              <div  class="publication">
                <div class="title-line">
                    <a href="http://ofey.me/projects/cetd/">
                  DOM Based Content Extraction via Text Density
              </a>
                </div>
                <div class="author-line">
                  <strong>Fei Sun </strong> , Dandan Song and Lejian Liao
                </div>
                <div class="author-line">
                  international ACM SIGIR conference (SIGIR 2011) <br>
                    { <a href="./papers/cetd-sigir11.pdf">PDF</a> | <a href="https://github.com/FeiSun/ContentExtraction">Code</a> | <a href="">Abstract</a> | <a href="">BibTeX</a> }
                  </div>

                  <div class="abstract" style="display: none; ">
                    <h3 id="abstract">Abstract</h3>

                    <p>Besides main contents, most web pages also consist of navigational panels, advertisements, copyrights and disclaimer notices. These additional contents, being typically not related to the main subject, may hamper the performance of web data mining, and thus are noises need to be removed properly. In this paper, we present Content Extraction via Text Density (CETD) – a fast, accurate and general method to extract contents from diverse web pages and keep their original structures using their DOM nodes’ text density. For this purpose, we introduce two concepts to measure the importance of the nodes: Text Density and Composite Text Density. And in order to extract intact contents, we propose a technique called DensitySum instead of Data Smoothing. The approach is evaluated on the CleanEval benchmark and random selected pages from well-known websites, where various web domains and styles are tested. By comparing against several alternative methods, the average F1-scores of our method is 8.79% higher than the best one of others. </p>
                  </div>
                  <div class="bibtex">
                    <h3 id="bibtex">BibTeX</h3>
                    <pre><code>
@inproceedings{Sun:2011:DBC:2009916.2009952,
author = {Sun, Fei and Song, Dandan and Liao, Lejian},
title = {DOM based content extraction via text density},
booktitle = {Proceedings of the 34th international ACM SIGIR conference on Research and development in Information Retrieval},
series = {SIGIR '11},
year = {2011},
isbn = {978-1-4503-0757-4},
location = {Beijing, China},
pages = {245--254},
numpages = {10},
url = {http://doi.acm.org/10.1145/2009916.2009952},
doi = {10.1145/2009916.2009952},
acmid = {2009952},
publisher = {ACM},
address = {New York, NY, USA},
keywords = {composite text density, content extraction, densitysum, text density},
}
                      </code>
{<a href="./bibtex/cetd-sigir11.bib">download</a>}</pre>
                  </div>

                </div>
                <!--end of one paper-->

              </div>

           <h2 id='journal_papers'>Journal Papers</h2>

            <div class="section">
            <h2 id="2015">2015</h2>

            <!--end of one paper-->
            <div class="publication">
              <div class="title-line">
                A hybrid approach for content extraction with text density and visual importance of DOM nodes
              </div>
              <div class="author-line">
               Dandan Song, <strong>Fei Sun</strong> and Lejian Liao
              </div>
              <div class="author-line">
                Knowledge and Information Systems<br>
                  { <a href="./papers/A hybrid approach for content extraction with text density and visual importance of DOM nodes.pdf">PDF</a> | <a href="">Abstract</a> | <a href="">BibTeX</a> }
                </div>

                <div class="abstract" style="display: none; ">
                  <h3 id="abstract">Abstract</h3>

                  <p>Additional contents in web pages, such as navigation panels, advertisements, copyrights and disclaimer notices, are typically not related to the main subject and may hamper the performance of Web data mining. They are traditionally taken as noises and need to be removed properly. To achieve this, two intuitive and crucial kinds of information—the textual information and the visual information of web pages—is considered in this paper. Accordingly, Text Density and Visual Importance are defined for the Document Object Model (DOM) nodes of a web page. Furthermore, a content extraction method with these measured values is proposed. It is a fast, accurate and general method for extracting content from diverse web pages. And with the employment of DOM nodes, the original structure of the web page can be preserved. Evaluated with the CleanEval benchmark and with randomly selected pages from well-known Web sites, where various web domains and styles are tested, the effect of the method is demonstrated. The average F1-scores with our method were 8.7 % higher than the best scores among several alternative methods.</p>
                </div>
                <div class="bibtex">
                  <h3 id="bibtex">BibTeX</h3>
                  <pre><code>
@article{Dan:hybrid2015,
year={2015},
issn={0219-1377},
journal={Knowledge and Information Systems},
volume={42},
number={1},
doi={10.1007/s10115-013-0687-x},
title={A hybrid approach for content extraction with text density and visual importance of DOM nodes},
url={http://dx.doi.org/10.1007/s10115-013-0687-x},
publisher={Springer London},
keywords={Content extraction; Text density; Visual importance},
author={Song, Dandan and Sun, Fei and Liao, Lejian},
pages={75-96},
language={English}
}

                    </code>
{<a href="./bibtex/A hybrid approach for content extraction with text density and visual importance of DOM nodes.bib">download</a>}</pre>
                </div>

                          </div>
                          <!--end of one paper-->

                        </div>


            </div>
            <!-- End Page -->


            <div id="footer">
  	          <address>
  		        <span class="copyright">
  			      Modify & Content by <a href="/">Ofey</a>. Design by
  			      <a href="http://mark.reid.name/">Mark Reid</a>
  			      <br/>
  		          <!--	(<a rel="licence" href="http://creativecommons.org/licenses/by-nc-sa/3.0/">Some rights reserved</a>)		-->
  		        </span>

  	          </address>
            </div>

          </div>

          <!--[if IE 6]>
              <script type="text/javascript">
	            /*Load jQuery if not already loaded*/ if(typeof jQuery == 'undefined'){ document.write("<script type=\"text/javascript\"   src=\"http://ajax.googleapis.com/ajax/libs/jquery/1.3.2/jquery.min.js\"></"+"script>"); var __noconflict = true; }
	            var IE6UPDATE_OPTIONS = {
		        icons_path: "http://static.ie6update.com/hosted/ie6update/images/"
	            }
              </script>
              <script type="text/javascript" src="http://static.ie6update.com/hosted/ie6update/ie6update.js"></script>
              <![endif]-->

          <a href="http://www.catb.org/hacker-emblem/"></a>
        </body>
      </html>
